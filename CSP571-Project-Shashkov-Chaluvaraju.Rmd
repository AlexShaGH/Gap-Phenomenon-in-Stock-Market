---
title: "CSP571 Summer 2022 Project. Gap Phenomenon in Stock Market: Evaluating the Significance of Price Gaps in Predicting Future Returns Using Statistical and Machine Learning Techniques"
output: 
  html_notebook: 
    toc: yes
    toc_float: yes
    toc_depth: 6
author: Oleksandr Shashkov and Santosh Chaluvaraju
        Illinois Institute of Technology
---

##LIBRARIES
```{r}
library(tibble)
library(collections)
library(tidyverse)
library(tidyquant)
library(lubridate)
library(dplyr)
library(timetk)
library(quantmod)
```

## SANTOSH CODE TO prepare dictionary (Please change the csv path) (Buggy Code needs fix)
```{r}
rm(list = ls())
```

```{r}
getList <- function(str, delimiter)
{
  return (unique(unlist(strsplit(str,delimiter))))
}
```

```{r}
df <- read.csv("/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/S&P 500 Historical Components & Changes(03-14-2022).csv")

#list of ticker list
listOfTkrList<- list()
for (x in 1:2648) {
  #getting ticker list of each row i.e. for a particular date 
    listOfTkrList[[x]] <- getList(df[x,2], ",")
}
#creating ticker period dictionary
tkrperiodDict <- dict()
x <- 1

#Iterating over list of ticker list
for (tkrList in listOfTkrList) {
  #Date of row x
  startDate <- df[x,1]
  
  #Iterating over each ticker in each list
  for (tkr in listOfTkrList[[x]]) {
    y <- x + 1
    #Iterating over each list after "tkrList" in list of lists i.e. listOfTkrList
    for (i in y:2648) {
      if(tkr %in% listOfTkrList[[i]]){
        index = which(listOfTkrList[[i]] == tkr)
        listOfTkrList[[i]] <- listOfTkrList[[i]][-index]
        endDate = df[i,1]
      }else{
        #If dictionary already has the key append the list
        if(tkrperiodDict$has(tkr)){
          periodList <- tkrperiodDict$get(tkr)
          tkrperiodDict$set(tkr, append(periodList, list(list(startDate, endDate))))
        }
        # ELSE make a new entry
        else{
          tkrperiodDict$set(tkr, list(list(startDate, endDate)))
        }
        break
      }
    }
    
  }
  
  x <- x + 1
  if(x == 2648){
    break
  }
  
}

```
```{r}
print(tkrperiodDict$get("AAL"))
```
## END SANtOSH CODE

# 1. Removing Survival Bias
```{r}
# mock up dictionary using list of lists to emulate ticker-ranges pairs
# tickers <- c("AAL","AAMRQ","AAPL")
# AAL1 <- list(as.Date("1/2/1996","%m/%d/%Y"),as.Date("1/13/1997","%m/%d/%Y"))
# AAL2 <- list(as.Date("3/23/2015","%m/%d/%Y"),as.Date("3/2/2022","%m/%d/%Y"))
# AAL <- list(AAL1,AAL2)
# AAMRQ <- list(list(as.Date("1/2/1996","%m/%d/%Y"),as.Date("3/10/2003","%m/%d/%Y")))
# AAPL <- list(list(as.Date("1/2/1996","%m/%d/%Y"),as.Date("3/2/2022","%m/%d/%Y")))
# ranges <- list(AAL,AAMRQ,AAPL)
# sp500_composition <- dict(items = ranges, keys = tickers)
# rm(AAL,AAL1,AAL2,AAMRQ,AAPL,ranges,tickers)
```

```{r}
# load the S&P500 historical composition
#SnP_components_raw <- read.csv("/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/S&P 500 Historical Components & Changes(03-14-2022).csv")

SnP_components_raw <- read.csv(file=file.choose())
```
```{r}
# form a set of all stocks tickers
tickers_set <- c()
for (composition in SnP_components_raw$tickers) {
  curr_composition <- strsplit(composition,split = ",")
  tickers_set <- unique(c(tickers_set,curr_composition[[1]]))
}
```
```{r}
# form a dictionary where a key is a ticker 
# and a value is a list of data ranges when a stock was in the S&P index

sp500_composition <- dict()
counter = 1
# iterate through the list of historical S&P components
for (tcr in tickers_set) {
  cat("Processing ticker:",tcr,"(",counter,")","\n")
  listed <- FALSE
  # declare time stamp variables
  start_timestamp <- Sys.Date()
  last_timestamp <- Sys.Date()
  # list of ranges when the current stock was a part of S&P index
  range_list <- list()
  # iterate through the time steps
  for (i in 1:nrow(SnP_components_raw)) {
    timestep <- SnP_components_raw[i,]
    curr_timestamp <- timestep$date[[1]][1]
    if (!(tcr %in% strsplit(timestep$tickers,split = ",")[[1]])){
      # ticker is not in the current composition
      if (listed){# stock was listed before but now it is not
        # form an entry in the list containing start and stop time stamps
        range_entry <- list(start_timestamp,last_timestamp)
        # add it to the list of ranges
        range_list <- append(range_list, list(range_entry))
        
        listed = FALSE
      }
    } else {# ticker is in the current composition
      if (!listed){# stock was not listed previously
        # start tracking new range
        start_timestamp <- curr_timestamp
        listed = TRUE
      }
    }
    last_timestamp <- curr_timestamp
  }
  # we are done with current ticker
  if (listed){  # need to check if the range needs to be closed
    # form an entry in the list containing start and stop time stamps
    range_entry <- list(start_timestamp,last_timestamp)
    # add it to the list of ranges
    range_list <- append(range_list, list(range_entry))
  }
  # add ticker and ranges to global dictionary
  sp500_composition$set(tcr,c(range_list))
  counter <- counter + 1
}

```


```{r}
# process dictionary to download stocks data for the ranges
for (stock in sp500_composition$keys()) {
  for (rng in sp500_composition$get(stock)){
    cat("ticker:",stock,"start:",
        format.Date(rng[[1]][1]),
        "stop:",format.Date(rng[[2]][1]),"\n")
    # download stocks data here having ticker and time stamps. tq_get returns data in tibble form, convert tibble data into dataframe before saving
    stock_prices_df <- as.data.frame(tq_get(stock, from = rng[[1]][1], to = rng[[2]][1]))
    # save it to the file
    file_name <- paste(stock,rng[[1]][1],"-",rng[[2]][1], sep = "-")
    #Putting all the files inside data folder
    file_name <- paste("data",file_name,sep = "/")
    file_name <- paste(file_name,"csv", sep = ".")
    write.csv(stock_prices_df , file_name, row.names = FALSE)
  }
}
```

#Downloading S&P500 index GSPC stock data
```{r}
# gfpcdf <- as.data.frame(getSymbols("^GSPC", auto.assign = FALSE, from= "1985-01-01", src="yahoo"))
# gfpcdf <- tibble::rownames_to_column(gfpcdf, "Date")
# #Putting SPX data file inside data folder
# file_name <- paste("data","GSPC",sep = "/")
# file_name <- paste(file_name,"csv", sep = ".")
# write.csv(gfpcdf , file_name, row.names = FALSE)
```
# Alex's version of the same 
# But with the column names matching other stocks
```{r}
# get S&P500 data for the entire data range:
GSPC <- getSymbols("^GSPC", auto.assign=FALSE, from="1996-01-01", src="yahoo")
GSPC_data <- data.frame(symbol='GSPC',date=time(GSPC),as.matrix(GSPC))
colnames(GSPC_data ) <- c("symbol","date","open","high","low","close","volume","adjusted")
write.csv(GSPC_data,"C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\data\\GSPC.csv", row.names = FALSE)
```

# NOT NECESSARY if your data folder has all the files downloaded from GIT, because git has data files which are appropriate
#Get all CSV files along with their full path
#Remove CSV files of tickers with in appropriate data
```{r}
path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/data" 
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)

for (file in filesList) {
  #Remove files if it contains less than or equal to 2 columns
  if(ncol(read.csv(file)) <= 2){
    file.remove(file)
  }
  
}
```

#Get all CSV files along with their full path
```{r}
#path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/data"

path <- "C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\data"
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)
```

#Function to detect gaps
```{r}
detect_gaps <- function(last_h, last_l, h, l)
{
  gap_size = 0.0
  gap_type = "NONE"
  if(last_l > h){
    gap_type = "DOWN"
    gap_size = (h - last_l)/last_l
  }
  else if(last_h < l){
    gap_type = "UP"
    #gap_size = (l - last_h)/last_h
    gap_size = as.numeric((l - last_h)/last_h)    
  }
  gap_list = list(gap_type, gap_size)
  
  return (gap_list)
}
```

#Preprocessing SPX(S&P 500 index) ticker data
```{r}
# spxdf <- read.csv("data/GSPC.csv")
# spxDailyReturns <- list()
# for(i in 1:nrow(spxdf)){
#   #calculating daily returns and storing it in spxDailyReturns list
#   spxDailyReturns <- append(spxDailyReturns, (spxdf[i,5] - spxdf[i,2]) / spxdf[i,2])
#   
# }
# #adding dailyReturns column
# spxdf$spxdailyReturns <- spxDailyReturns
# 
# #Putting pre processed file inside pre_processed_data folder
# file_name <- paste("GSPC", "preprocessed", sep = "_" )
# file_name <- paste("pre_processed_data",file_name,sep = "/")
# file_name <- paste(file_name,"csv", sep = ".")
# spxdf <- apply(spxdf,2,as.character)
# write.csv(spxdf , file_name, row.names = FALSE)
```

```{r}
# loading data and calculating overnight returns for S&P500 index
spxdf <- read.csv("data/GSPC.csv")
rownames(spxdf) <- spxdf$date
for(i in 1:nrow(spxdf)){
      if(i == 1){
        # fake overnight return with intraday for first entry
        spxdf$return[i] <- (spxdf$close[i]-spxdf$open[i])/spxdf$open[i]
      }
      else{
        spxdf$return[i] <- (spxdf$adjusted[i]-spxdf$adjusted[i-1])/spxdf$adjusted[i-1]
      }
}

#Putting pre processed file inside pre_processed_data folder
file_name <- paste("GSPC", "preprocessed", sep = "_" )
file_name <- paste("pre_processed_data",file_name,sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
spxdf <- apply(spxdf,2,as.character)
write.csv(spxdf , file_name, row.names = FALSE)

# reload spxdf
spxdf <- read.csv("pre_processed_data/GSPC_preprocessed.csv")
rownames(spxdf) <- spxdf$date
```


#Preprocessing: Detecting gaps and types, Calculating ranges, relative volume, daily returns and adjusted daily returns and adding it into new columns 
```{r}
for (file in filesList) {
  # load CSV file  
  df <- read.csv(file)
  print(file)
  
  df <- df[!is.na(df$high),]
  df <- df[!is.na(df$low),]
  # Perform preprocessing only if the data frame has more than 25 rows else ignore
  if(nrow(df) > 25){
    
    gap_list <- list()
    
    for(i in 1:nrow(df)){
      if(i == 1){
        gap_list[[i]] <- list("NONE", 0.0)
        df$vol_change[i] <- 0.0
        # fake overnight return with intraday for first entry
        df$return[i] <- (df$close[i]-df$open[i])/df$open[i]
      }
      else{
        gap_list[[i]] <- detect_gaps(df$high[i-1], df$low[i-1], df$high[i], df$low[i])
        # calculating relative volume
        df$vol_change[i] <- (df$volume[i] - df$volume[i-1])/df$volume[i-1]
        # calculating daily returns
        # We need overnight return, not intraday
        # And we need to use adjusted close for that
        df$return[i] <- (df$adjusted[i]-df$adjusted[i-1])/df$adjusted[i-1]
      }
      
      #calculating adjusted returns
      df$adjusted_return[i] <- df$return[i] - spxdf$return[which(rownames(spxdf)==df$date[i])]
      
    }
    df_temp <- as.data.frame(do.call(rbind, gap_list))
    colnames(df_temp) <- c("gap_type", "gap_size")
    df <- cbind(df, df_temp)
    #adding range column
    df$range <- (df$high - df$low)/df$low
    
    # extract day of the week and month as potential features
    df$weekday <- wday(df$date, week_start=1)
    df$month <- month(df$date)
    
    # calculate "candle body metric"
    df$candle_body_metric <- (df$close - df$open)/df$open

    # adding lags and leads
    selected_cols <- c(
      "vol_change","return","adjusted_return","range","weekday","month","candle_body_metric")
    lags_leads <- (-10:10)[as.logical( -10:10 != 0)]# -10...-1 1...10 - omit 0 
    df <- df %>% tk_augment_lags(contains(selected_cols), .lags = lags_leads)    

    # cleaning up rows with NAs
    df <- na.omit(df)

    #Putting all the pre processed files inside pre_processed_data folder
    file_name <- paste(sub('\\.csv$', '', basename(file)), "preprocessed", sep = "_" )
    file_name <- paste("pre_processed_data",file_name,sep = "/")
    file_name <- paste(file_name,"csv", sep = ".")
    df <- apply(df,2,as.character)
    write.csv(df , file_name, row.names = FALSE)
    # debug
    #break
  }
  
}
```

# save all the gaps into a single dataframe, preserve it inot CSV
```{r}
#path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/pre_processed_data"

path <- "C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\pre_processed_data"
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)
# remove file describing index
filesList <- filesList[!grepl("GSPC",filesList)]
# isFirstFile <- TRUE
# for (file in filesList) {
#   print(file)
#   df <- read.csv(file)
#   df <- df[df$gap_type %in% c('DOWN', 'UP'), ]
#   if(isFirstFile){
#     final_stock_df <- df
#     isFirstFile <- FALSE
#   }else{
#     final_stock_df <- rbind(final_stock_df, df)
#   }
final_stock_df <- data.frame()
for (file in filesList) {
  print(file)
  df <- read.csv(file)
  df <- df[df$gap_type !='NONE',]
  final_stock_df <- rbind(final_stock_df, df)
}
  
print(nrow(final_stock_df))

#Putting all the pre processed files inside pre_processed_data folder
file_name <- paste("final", "preprocessed", sep = "_" )
file_name <- paste("final_pre_processed_data",file_name,sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
write.csv(final_stock_df , file_name, row.names = FALSE)
```

```{r}
#cleanup
rm(list=ls())
```

# Final clenup
```{r}
# load dataframe with gaps
#file < - "C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\final_pre_processed_data\\final_preprocessed.csv"
file <- file.choose()
gaps_df <- read.csv(file)

```

```{r}
dim(gaps_df)
summary(gaps_df)
```
# the data has to be cleaned as there are: 
1) inf values in vol_change column and lags
2) Enormously high returns in some rows and lags
3) Enormously high ranges in some rows and lags
4) Enormously high gaps in some rows and lags
5) gap_type must be a factor
6) weekday and month and their lags must be factors

```{r}
summary(gaps_df$vol_change)
quantile(gaps_df$vol_change,probs=c(.01,.99))
hist(gaps_df$vol_change, breaks=1000, main = "Volume change distirbution before the cleanup")
hist(log(gaps_df$vol_change), breaks=1000, main = "Log Volume change distirbution before the cleanup")
```

```{r}
# removing rows with infinite and unrealistic values of vol_change and its lags
# let's limit it within at least 98% range:  ( -0.642356 < and < 8.261169 )
mx = 8.27
mn = -0.64
gaps_df <- gaps_df[gaps_df$vol_change < mx &  gaps_df$vol_change > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.10 < mx &  gaps_df$vol_change_lag.10 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.9 < mx &  gaps_df$vol_change_lag.9 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.8 < mx &  gaps_df$vol_change_lag.8 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.7 < mx &  gaps_df$vol_change_lag.7 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.6 < mx &  gaps_df$vol_change_lag.6 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.5 < mx &  gaps_df$vol_change_lag.5 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.4 < mx &  gaps_df$vol_change_lag.4 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.3 < mx &  gaps_df$vol_change_lag.3 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.2 < mx &  gaps_df$vol_change_lag.2 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.1 < mx &  gaps_df$vol_change_lag.1 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag10 < mx &  gaps_df$vol_change_lag10 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag9 < mx &  gaps_df$vol_change_lag9 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag8 < mx &  gaps_df$vol_change_lag8 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag7 < mx &  gaps_df$vol_change_lag7 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag6 < mx &  gaps_df$vol_change_lag6 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag5 < mx &  gaps_df$vol_change_lag5 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag4 < mx &  gaps_df$vol_change_lag4 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag3 < mx &  gaps_df$vol_change_lag3 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag2 < mx &  gaps_df$vol_change_lag2 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag1 < mx &  gaps_df$vol_change_lag1 > mn,]

```

```{r}
summary(gaps_df$vol_change)
hist(gaps_df$vol_change, breaks=100, main = "Volume change distribution after the cleanup")

```

# this took care of all the unreasonable values!!!

```{r}
gaps_df$gap_type <- as.factor(gaps_df$gap_type)
gaps_df$weekday <- as.factor(gaps_df$weekday)
gaps_df$month <- as.factor(gaps_df$month)

gaps_df$weekday_lag.10 <- as.factor(gaps_df$weekday_lag.10)
gaps_df$month_lag.10 <- as.factor(gaps_df$month_lag.10)
gaps_df$weekday_lag.9 <- as.factor(gaps_df$weekday_lag.9)
gaps_df$month_lag.9 <- as.factor(gaps_df$month_lag.9)
gaps_df$weekday_lag.8 <- as.factor(gaps_df$weekday_lag.8)
gaps_df$month_lag.8 <- as.factor(gaps_df$month_lag.8)
gaps_df$weekday_lag.7 <- as.factor(gaps_df$weekday_lag.7)
gaps_df$month_lag.7 <- as.factor(gaps_df$month_lag.7)
gaps_df$weekday_lag.6 <- as.factor(gaps_df$weekday_lag.6)
gaps_df$month_lag.6 <- as.factor(gaps_df$month_lag.6)
gaps_df$weekday_lag.5 <- as.factor(gaps_df$weekday_lag.5)
gaps_df$month_lag.5 <- as.factor(gaps_df$month_lag.5)
gaps_df$weekday_lag.4 <- as.factor(gaps_df$weekday_lag.4)
gaps_df$month_lag.4 <- as.factor(gaps_df$month_lag.4)
gaps_df$weekday_lag.3 <- as.factor(gaps_df$weekday_lag.3)
gaps_df$month_lag.3 <- as.factor(gaps_df$month_lag.3)
gaps_df$weekday_lag.2 <- as.factor(gaps_df$weekday_lag.2)
gaps_df$month_lag.2 <- as.factor(gaps_df$month_lag.2)
gaps_df$weekday_lag.1 <- as.factor(gaps_df$weekday_lag.1)
gaps_df$month_lag.1 <- as.factor(gaps_df$month_lag.1)

gaps_df$weekday_lag10 <- as.factor(gaps_df$weekday_lag10)
gaps_df$month_lag10 <- as.factor(gaps_df$month_lag10)
gaps_df$weekday_lag9 <- as.factor(gaps_df$weekday_lag9)
gaps_df$month_lag9 <- as.factor(gaps_df$month_lag9)
gaps_df$weekday_lag8 <- as.factor(gaps_df$weekday_lag8)
gaps_df$month_lag8 <- as.factor(gaps_df$month_lag8)
gaps_df$weekday_lag7 <- as.factor(gaps_df$weekday_lag7)
gaps_df$month_lag7 <- as.factor(gaps_df$month_lag7)
gaps_df$weekday_lag6 <- as.factor(gaps_df$weekday_lag6)
gaps_df$month_lag6 <- as.factor(gaps_df$month_lag6)
gaps_df$weekday_lag5 <- as.factor(gaps_df$weekday_lag5)
gaps_df$month_lag5 <- as.factor(gaps_df$month_lag5)
gaps_df$weekday_lag4 <- as.factor(gaps_df$weekday_lag4)
gaps_df$month_lag4 <- as.factor(gaps_df$month_lag4)
gaps_df$weekday_lag3 <- as.factor(gaps_df$weekday_lag3)
gaps_df$month_lag3 <- as.factor(gaps_df$month_lag3)
gaps_df$weekday_lag2 <- as.factor(gaps_df$weekday_lag2)
gaps_df$month_lag2 <- as.factor(gaps_df$month_lag2)
gaps_df$weekday_lag1 <- as.factor(gaps_df$weekday_lag1)
gaps_df$month_lag1 <- as.factor(gaps_df$month_lag1)

summary(gaps_df)
```
```{r}
# Saving clean data frame
file_name <- paste("clean", "preprocessed", sep = "_" )
file_name <- paste("final_pre_processed_data",file_name,sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
write.csv(gaps_df , file_name, row.names = FALSE)
```
```{r}
#cleanup
rm(list=ls())
```
# run statistical analysis, produce graphs - i.e. correlations, distributions, etc. - anything to gain information about gaps
```{r}
# load clean dataframe with gaps
file <- file.choose()
gaps_df <- read.csv(file)
gaps_df$gap_type <- as.factor(gaps_df$gap_type)
gaps_df$weekday <- as.factor(gaps_df$weekday)
gaps_df$month <- as.factor(gaps_df$month)

gaps_df$weekday_lag.10 <- as.factor(gaps_df$weekday_lag.10)
gaps_df$month_lag.10 <- as.factor(gaps_df$month_lag.10)
gaps_df$weekday_lag.9 <- as.factor(gaps_df$weekday_lag.9)
gaps_df$month_lag.9 <- as.factor(gaps_df$month_lag.9)
gaps_df$weekday_lag.8 <- as.factor(gaps_df$weekday_lag.8)
gaps_df$month_lag.8 <- as.factor(gaps_df$month_lag.8)
gaps_df$weekday_lag.7 <- as.factor(gaps_df$weekday_lag.7)
gaps_df$month_lag.7 <- as.factor(gaps_df$month_lag.7)
gaps_df$weekday_lag.6 <- as.factor(gaps_df$weekday_lag.6)
gaps_df$month_lag.6 <- as.factor(gaps_df$month_lag.6)
gaps_df$weekday_lag.5 <- as.factor(gaps_df$weekday_lag.5)
gaps_df$month_lag.5 <- as.factor(gaps_df$month_lag.5)
gaps_df$weekday_lag.4 <- as.factor(gaps_df$weekday_lag.4)
gaps_df$month_lag.4 <- as.factor(gaps_df$month_lag.4)
gaps_df$weekday_lag.3 <- as.factor(gaps_df$weekday_lag.3)
gaps_df$month_lag.3 <- as.factor(gaps_df$month_lag.3)
gaps_df$weekday_lag.2 <- as.factor(gaps_df$weekday_lag.2)
gaps_df$month_lag.2 <- as.factor(gaps_df$month_lag.2)
gaps_df$weekday_lag.1 <- as.factor(gaps_df$weekday_lag.1)
gaps_df$month_lag.1 <- as.factor(gaps_df$month_lag.1)

gaps_df$weekday_lag10 <- as.factor(gaps_df$weekday_lag10)
gaps_df$month_lag10 <- as.factor(gaps_df$month_lag10)
gaps_df$weekday_lag9 <- as.factor(gaps_df$weekday_lag9)
gaps_df$month_lag9 <- as.factor(gaps_df$month_lag9)
gaps_df$weekday_lag8 <- as.factor(gaps_df$weekday_lag8)
gaps_df$month_lag8 <- as.factor(gaps_df$month_lag8)
gaps_df$weekday_lag7 <- as.factor(gaps_df$weekday_lag7)
gaps_df$month_lag7 <- as.factor(gaps_df$month_lag7)
gaps_df$weekday_lag6 <- as.factor(gaps_df$weekday_lag6)
gaps_df$month_lag6 <- as.factor(gaps_df$month_lag6)
gaps_df$weekday_lag5 <- as.factor(gaps_df$weekday_lag5)
gaps_df$month_lag5 <- as.factor(gaps_df$month_lag5)
gaps_df$weekday_lag4 <- as.factor(gaps_df$weekday_lag4)
gaps_df$month_lag4 <- as.factor(gaps_df$month_lag4)
gaps_df$weekday_lag3 <- as.factor(gaps_df$weekday_lag3)
gaps_df$month_lag3 <- as.factor(gaps_df$month_lag3)
gaps_df$weekday_lag2 <- as.factor(gaps_df$weekday_lag2)
gaps_df$month_lag2 <- as.factor(gaps_df$month_lag2)
gaps_df$weekday_lag1 <- as.factor(gaps_df$weekday_lag1)
gaps_df$month_lag1 <- as.factor(gaps_df$month_lag1)
rm(file)
```
```{r}
total_gaps <- nrow(gaps_df)
cat("Total number of gaps detected:", total_gaps, "\n")
gap_types <- summary(gaps_df$gap_type)
up_gaps <-unname(gap_types['UP'])
down_gaps <- unname(gap_types['DOWN'])
cat("Gaps UP:", up_gaps,round(100*up_gaps/total_gaps,digits = 2),"%","\n")
cat("Gaps DOWN:", down_gaps,round(100*down_gaps/total_gaps,digits = 2),"%","\n")
```
```{r}
# gaps per weekday
cat("Gaps per weekday:\n")
round(prop.table(table(gaps_df$weekday)) * 100, digits = 2)
cat("Gaps UP per weekday:\n")
round(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='UP'])) * 100, digits = 2)
cat("Gaps DOWN per weekday:\n")
round(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='DOWN'])) * 100, digits = 2)
xl <- "Day of the week"
yl <- "Percentage"
par(mfrow=c(2,2))
barplot(prop.table(table(gaps_df$weekday)) * 100, main = "Gaps per weekday", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='UP'])) * 100, main = "Gaps UP per weekday", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='DOWN'])) * 100, main = "Gaps DOWN per weekday", xlab = xl, ylab = yl)
```
```{r}
# gaps per month
cat("Gaps per month:\n")
round(prop.table(table(gaps_df$month)) * 100, digits = 2)
cat("Gaps UP per month:\n")
round(prop.table(table(gaps_df$month[gaps_df$gap_type =='UP'])) * 100, digits = 2)
cat("Gaps DOWN per month:\n")
round(prop.table(table(gaps_df$month[gaps_df$gap_type =='DOWN'])) * 100, digits = 2)
xl <- "Month of the year"
yl <- "Percentage"
par(mfrow=c(2,2))
barplot(prop.table(table(gaps_df$month)) * 100, main = "Gaps per month", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$month[gaps_df$gap_type =='UP'])) * 100, main = "Gaps UP per month", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$month[gaps_df$gap_type =='DOWN'])) * 100, main = "Gaps DOWN per month", xlab = xl, ylab = yl)
```
```{r}
# Gap sizes
qu <- quantile(gaps_df$gap_size[gaps_df$gap_size > 0],probs=c(.05,.95))
ql <- quantile(gaps_df$gap_size[gaps_df$gap_size < 0],probs=c(.05,.95))
xl <- "Gap size, %"
yl <- "Frequency"
par(mfrow=c(2,2))
hist(100*gaps_df$gap_size[gaps_df$gap_size > 0], breaks=10000, main = "Gap UP size distribution, all", xlab = xl, ylab = yl, col = "green")
hist(-100*gaps_df$gap_size[gaps_df$gap_size < 0], breaks=10000, main = "Gap DOWN size distribution, all", xlab = xl, ylab = yl, col = "red")
hist(100*gaps_df$gap_size[gaps_df$gap_size > 0 & gaps_df$gap_size < unname(qu["95%"])], breaks=50, main = "Gap UP size distribution, 95%", xlab = xl, ylab = yl, col = "green")
hist(-100*gaps_df$gap_size[gaps_df$gap_size < 0 & gaps_df$gap_size > unname(ql["5%"])], breaks=50, main = "Gap DOWN size distribution. 95%", xlab = xl, ylab = yl, col = "red")
qu
ql
```

```{r}
# Gap candle range
q <- quantile(gaps_df$range,probs=c(.01,.99))
qu <- quantile(gaps_df$range[gaps_df$gap_type == "UP"],probs=c(.01,.99))
qd <- quantile(gaps_df$range[gaps_df$gap_type == "DOWN"],probs=c(.01,.99))
xl <- "Range, %"
yl <- "Frequency"
par(mfrow=c(3,2))
hist(100*gaps_df$range, breaks=10000, main = "Gap candle range distribution, all", xlab = xl, ylab = yl)
hist(100*gaps_df$range[gaps_df$range < unname(q["99%"])], breaks=50, main = "Gap candle range distribution, 99%", xlab = xl, ylab = yl)

hist(100*gaps_df$range[gaps_df$gap_type == "UP"], breaks=10000, main = "Gap UP candle range distribution, all", xlab = xl, ylab = yl)
hist(100*gaps_df$range[gaps_df$gap_type == "UP" & gaps_df$range < unname(qu["99%"])], breaks=50, main = "Gap UP candle range distribution, 99%", xlab = xl, ylab = yl, col = "green")

hist(100*gaps_df$range[gaps_df$gap_type == "DOWN"], breaks=10000, main = "Gap DOWN candle range distribution, all", xlab = xl, ylab = yl)
hist(100*gaps_df$range[gaps_df$gap_type == "DOWN" & gaps_df$range < unname(qd["99%"])], breaks=50, main = "Gap DOWN candle range distribution, 99%", xlab = xl, ylab = yl, col = "red")

```
```{r}
# Gap candle body metric
q <- quantile(gaps_df$candle_body_metric,probs=c(.01,.99))
qu <- quantile(gaps_df$candle_body_metric[gaps_df$gap_type == "UP"],probs=c(.01,.99))
qd <- quantile(gaps_df$candle_body_metric[gaps_df$gap_type == "DOWN"],probs=c(.01,.99))
xl <- "Body Metric, %"
yl <- "Frequency"
par(mfrow=c(3,2))
hist(100*gaps_df$candle_body_metric[gaps_df$candle_body_metric < unname(q["99%"]) & gaps_df$candle_body_metric > unname(q["1%"])], breaks=50, main = "Gap candle body metric distribution", xlab = xl, ylab = yl)
boxplot(100*gaps_df$candle_body_metric, horizontal = TRUE, main = "Gap candle body metric distribution")

hist(100*gaps_df$candle_body_metric[gaps_df$gap_type == "UP" & gaps_df$candle_body_metric < unname(qu["99%"]) & gaps_df$candle_body_metric > unname(qu["1%"])], breaks=50, main = "Gap UP candle body metric distribution", xlab = xl, ylab = yl,col = "green")
boxplot(100*gaps_df$candle_body_metric[gaps_df$gap_type == "UP" & gaps_df$candle_body_metric < unname(qu["99%"])& gaps_df$candle_body_metric > unname(qu["1%"])], horizontal = TRUE, main = "Gap UP candle body metric distribution", col = "green")

hist(100*gaps_df$candle_body_metric[gaps_df$gap_type == "DOWN" & gaps_df$candle_body_metric < unname(qd["99%"]) & gaps_df$candle_body_metric > unname(qd["1%"])], breaks=50, main = "Gap DOWN candle body metric distribution", xlab = xl, ylab = yl,col = "red")
boxplot(100*gaps_df$candle_body_metric[gaps_df$gap_type == "DOWN" & gaps_df$candle_body_metric < unname(qd["99%"])& gaps_df$candle_body_metric > unname(qd["1%"])], horizontal = TRUE, main = "Gap DOWN candle body metric distribution", col = "red")

```
```{r}
# Correlations
# Create a sub frame



```

```{r}
#cleanup
rm(list=ls())
```

# TODO: Model it and try to predict !!!!
we may limit it to just one day after the gap for the purpose of the project
