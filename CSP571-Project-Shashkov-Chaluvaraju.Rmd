---
title: "CSP571 Summer 2022 Project. Gap Phenomenon in Stock Market: Evaluating the Significance of Price Gaps in Predicting Future Returns Using Statistical and Machine Learning Techniques"
output: 
  html_notebook: 
    toc: yes
    toc_float: yes
    toc_depth: 6
author: Oleksandr Shashkov and Santosh Chaluvaraju
        Illinois Institute of Technology
---

##LIBRARIES
```{r}
library(tibble)
```

## SANTOSH CODE TO prepare dictionary (Please change the csv path) (Buggy Code needs fix)
```{r}
rm(list = ls())
```

```{r}
getList <- function(str, delimiter)
{
  return (unique(unlist(strsplit(str,delimiter))))
}
```

```{r}
df <- read.csv("/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/S&P 500 Historical Components & Changes(03-14-2022).csv")

#list of ticker list
listOfTkrList<- list()
for (x in 1:2648) {
  #getting ticker list of each row i.e. for a particular date 
    listOfTkrList[[x]] <- getList(df[x,2], ",")
}
#creating ticker period dictionary
tkrperiodDict <- dict()
x <- 1

#Iterating over list of ticker list
for (tkrList in listOfTkrList) {
  #Date of row x
  startDate <- df[x,1]
  
  #Iterating over each ticker in each list
  for (tkr in listOfTkrList[[x]]) {
    y <- x + 1
    #Iterating over each list after "tkrList" in list of lists i.e. listOfTkrList
    for (i in y:2648) {
      if(tkr %in% listOfTkrList[[i]]){
        index = which(listOfTkrList[[i]] == tkr)
        listOfTkrList[[i]] <- listOfTkrList[[i]][-index]
        endDate = df[i,1]
      }else{
        #If dictionary already has the key append the list
        if(tkrperiodDict$has(tkr)){
          periodList <- tkrperiodDict$get(tkr)
          tkrperiodDict$set(tkr, append(periodList, list(list(startDate, endDate))))
        }
        # ELSE make a new entry
        else{
          tkrperiodDict$set(tkr, list(list(startDate, endDate)))
        }
        break
      }
    }
    
  }
  
  x <- x + 1
  if(x == 2648){
    break
  }
  
}

```
```{r}
print(tkrperiodDict$get("AAL"))
```
## END SANtOSH CODE

# 1. Removing Survival Bias

```{r}
library(collections)
```
```{r}
# mock up dictionary using list of lists to emulate ticker-ranges pairs
# tickers <- c("AAL","AAMRQ","AAPL")
# AAL1 <- list(as.Date("1/2/1996","%m/%d/%Y"),as.Date("1/13/1997","%m/%d/%Y"))
# AAL2 <- list(as.Date("3/23/2015","%m/%d/%Y"),as.Date("3/2/2022","%m/%d/%Y"))
# AAL <- list(AAL1,AAL2)
# AAMRQ <- list(list(as.Date("1/2/1996","%m/%d/%Y"),as.Date("3/10/2003","%m/%d/%Y")))
# AAPL <- list(list(as.Date("1/2/1996","%m/%d/%Y"),as.Date("3/2/2022","%m/%d/%Y")))
# ranges <- list(AAL,AAMRQ,AAPL)
# sp500_composition <- dict(items = ranges, keys = tickers)
# rm(AAL,AAL1,AAL2,AAMRQ,AAPL,ranges,tickers)
```

```{r}
# load the S&P500 historical composition
#SnP_components_raw <- read.csv("/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/S&P 500 Historical Components & Changes(03-14-2022).csv")

SnP_components_raw <- read.csv(file=file.choose())
```
```{r}
# form a set of all stocks tickers
tickers_set <- c()
for (composition in SnP_components_raw$tickers) {
  curr_composition <- strsplit(composition,split = ",")
  tickers_set <- unique(c(tickers_set,curr_composition[[1]]))
}
```
```{r}
# form a dictionary where a key is a ticker 
# and a value is a list of data ranges when a stock was in the S&P index

sp500_composition <- dict()
counter = 1
# iterate through the list of historical S&P components
for (tcr in tickers_set) {
  cat("Processing ticker:",tcr,"(",counter,")","\n")
  listed <- FALSE
  # declare time stamp variables
  start_timestamp <- Sys.Date()
  last_timestamp <- Sys.Date()
  # list of ranges when the current stock was a part of S&P index
  range_list <- list()
  # iterate through the time steps
  for (i in 1:nrow(SnP_components_raw)) {
    timestep <- SnP_components_raw[i,]
    curr_timestamp <- timestep$date[[1]][1]
    if (!(tcr %in% strsplit(timestep$tickers,split = ",")[[1]])){
      # ticker is not in the current composition
      if (listed){# stock was listed before but now it is not
        # form an entry in the list containing start and stop time stamps
        range_entry <- list(start_timestamp,last_timestamp)
        # add it to the list of ranges
        range_list <- append(range_list, list(range_entry))
        
        listed = FALSE
      }
    } else {# ticker is in the current composition
      if (!listed){# stock was not listed previously
        # start tracking new range
        start_timestamp <- curr_timestamp
        listed = TRUE
      }
    }
    last_timestamp <- curr_timestamp
  }
  # we are done with current ticker
  if (listed){  # need to check if the range needs to be closed
    # form an entry in the list containing start and stop time stamps
    range_entry <- list(start_timestamp,last_timestamp)
    # add it to the list of ranges
    range_list <- append(range_list, list(range_entry))
  }
  # add ticker and ranges to global dictionary
  sp500_composition$set(tcr,c(range_list))
  counter <- counter + 1
}

```


```{r}
library(tidyverse)
library(tidyquant)
# process dictionary to download stocks data for the ranges
for (stock in sp500_composition$keys()) {
  for (rng in sp500_composition$get(stock)){
    cat("ticker:",stock,"start:",
        format.Date(rng[[1]][1]),
        "stop:",format.Date(rng[[2]][1]),"\n")
    # download stocks data here having ticker and time stamps. tq_get returns data in tibble form, convert tibble data into dataframe before saving
    stock_prices_df <- as.data.frame(tq_get(stock, from = rng[[1]][1], to = rng[[2]][1]))
    # save it to the file
    file_name <- paste(stock,rng[[1]][1],"-",rng[[2]][1], sep = "-")
    #Putting all the files inside data folder
    file_name <- paste("data",file_name,sep = "/")
    file_name <- paste(file_name,"csv", sep = ".")
    write.csv(stock_prices_df , file_name, row.names = FALSE)
  }
}
```

#Downloading S&P500 index GSPC stock data
```{r}
gfpcdf <- as.data.frame(getSymbols("^GSPC", auto.assign = FALSE, from= "1985-01-01", src="yahoo"))
gfpcdf <- tibble::rownames_to_column(gfpcdf, "Date")
#Putting SPX data file inside data folder
file_name <- paste("data","SPX",sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
write.csv(gfpcdf , file_name, row.names = FALSE)
```

# NOT NECESSARY if your data folder has all the files downloaded from GIT, because git has data files which are appropriate
#Get all CSV files along with their full path
#Remove CSV files of tickers with in appropriate data
```{r}
path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/data" 
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)

for (file in filesList) {
  #Remove files if it contains less than or equal to 2 columns
  if(ncol(read.csv(file)) <= 2){
    file.remove(file)
  }
  
}
```

#Get all CSV files along with their full path
```{r}
path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/data"

#path <- "C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\data"
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)
```

#Function to detect gaps
```{r}
detect_gaps <- function(last_h, last_l, h, l)
{
  gap_size = 0.0
  gap_type = "NONE"
  if(last_l > h){
    gap_type = "DOWN"
    gap_size = (h - last_l)/last_l
  }
  else if(last_h < l){
    gap_type = "UP"
    gap_size = (l - last_h)/last_h
  }
  gap_list = list(gap_type, gap_size)
  
  return (gap_list)
}
```

#Preprocessing SPX(S&P 500 index) ticker data
```{r}
spxdf <- read.csv("data/SPX.csv")
spxDailyReturns <- list()
for(i in 1:nrow(spxdf)){
  #calculating daily returns and storing it in spxDailyReturns list
  spxDailyReturns <- append(spxDailyReturns, (spxdf[i,5] - spxdf[i,2]) / spxdf[i,2])
  
}
#adding dailyReturns column
spxdf$spxdailyReturns <- spxDailyReturns

#Putting pre processed file inside pre_processed_data folder
file_name <- paste("SPX", "preprocessed", sep = "_" )
file_name <- paste("pre_processed_data",file_name,sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
spxdf <- apply(spxdf,2,as.character)
write.csv(spxdf , file_name, row.names = FALSE)
```

#Preprocessing: Detecting gaps and types, Calculating ranges, relative volume, daily returns and adjusted daily returns and adding it into new columns 
```{r}
library(lubridate)
spxdf <- read.csv("pre_processed_data/SPX_preprocessed.csv")
#set specific column as row names
rownames(spxdf) <- spxdf$Date

#remove original column from data frame
spxdf$Date <- NULL

for (file in filesList) {
  
  #print(file)
  #load CSV file  
  df <- read.csv(file)
  
  #Perform preprocessing only if the data frame has more than 25 rows else ignore
  if(nrow(df) > 25){
    
    gap_list <- list()
    range <- list()
    dailyReturns <- list()
    relativeVolume <- list()
    adjustedDailyReturns <- list()
    
    df <- df[!is.na(df$high),]
    df <- df[!is.na(df$low),]
    
    for(i in 1:nrow(df)){
      if(i == 1){
        gap_list[[i]] <- list("NONE", 0.0)
        relativeVolume <- append(relativeVolume, 0.0)
      }
      else{
        #print(i)
        gap_list[[i]] <- detect_gaps(df[i-1, 4], df[i-1, 5], df[i,4], df[i,5])
        #calculating relative volume
        relativeVolume <- append(relativeVolume, (df[i, 7] - df[i-1, 7])/df[i-1, 7])
      }
      #calculating range and storing it in range list
      range <- append(range, (df[i,4] - df[i,5]) / df[i,5])
      
      #calculating daily returns and storing it in dailyReturns list
      dr <- (df[i,6] - df[i,3]) / df[i,3]
      dailyReturns <- append(dailyReturns, dr)
      
      #calculating adjusted daily returns and storing it in adjustedDailyReturns list
      adjustedDailyReturns <- append(adjustedDailyReturns, spxdf[which(rownames(spxdf)==df[i,2]),7] - dr)
      
    }
    df_temp <- as.data.frame(do.call(rbind, gap_list))
    colnames(df_temp) <- c("gap_type", "gap_size")
    df <- cbind(df, df_temp)
    #adding range column
    df$range <- range
    
    #adding dailyReturns column
    df$dailyReturns <- dailyReturns
    
    #adding adjustedDailyReturns column
    df$adjustedDailyReturns <- adjustedDailyReturns
    
    #adding relativeVolume column
    df$relativeVolume <- relativeVolume
    
    # extract day of the week and month as potential features
    df$weekday <- wday(df$date, week_start=1)
    df$month <- month(mdy(df$date))
    
    #Putting all the pre processed files inside pre_processed_data folder
    file_name <- paste(sub('\\.csv$', '', basename(file)), "preprocessed", sep = "_" )
    file_name <- paste("pre_processed_data",file_name,sep = "/")
    file_name <- paste(file_name,"csv", sep = ".")
    df <- apply(df,2,as.character)
    write.csv(df , file_name, row.names = FALSE)
  }
  
}
```